{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/noorelhaj98-ship-it/pytorch-tutorial/blob/main/traffic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eMSVZdk_ks_a",
    "outputId": "84270eb1-c50d-4c2a-bd73-3b1683e172ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
      "Collecting pi-heif<2 (from roboflow)\n",
      "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting pillow-avif-plugin<2 (from roboflow)\n",
      "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.61.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
      "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.12.0.88\n",
      "    Uninstalling opencv-python-headless-4.12.0.88:\n",
      "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.11\n",
      "    Uninstalling idna-3.11:\n",
      "      Successfully uninstalled idna-3.11\n",
      "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Vechiles-2 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 499683/499683 [00:15<00:00, 32870.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Vechiles-2 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16102/16102 [00:03<00:00, 5021.75it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"snA4vsNSH6S3ia5q9egX\")\n",
    "project = rf.workspace(\"traffic-tmfdb\").project(\"vechiles-hq6la-r7fco\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZYEMTgFkvn2",
    "outputId": "64d2d88f-77a2-450d-bc11-9fa1097e1060"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 8048\n",
      "Total labels: 8048\n",
      "\n",
      "‚úÖ RESULT: Every image has a matching label and vice versa\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "images_dir = \"/content/Vechiles-2/train/images\"\n",
    "labels_dir = \"/content/Vechiles-2/train/labels\"\n",
    "\n",
    "image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "images = sorted([\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(images_dir)\n",
    "    if f.lower().endswith(image_exts)\n",
    "])\n",
    "\n",
    "labels = sorted([\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(labels_dir)\n",
    "    if f.lower().endswith(\".txt\")\n",
    "])\n",
    "\n",
    "print(\"Total images:\", len(images))\n",
    "print(\"Total labels:\", len(labels))\n",
    "\n",
    "image_set = set(images)\n",
    "label_set = set(labels)\n",
    "\n",
    "images_without_labels = image_set - label_set\n",
    "labels_without_images = label_set - image_set\n",
    "\n",
    "if not images_without_labels and not labels_without_images:\n",
    "    print(\"\\n‚úÖ RESULT: Every image has a matching label and vice versa\")\n",
    "else:\n",
    "    print(\"\\n‚ùå RESULT: Mismatches found\")\n",
    "\n",
    "    if images_without_labels:\n",
    "        print(\"\\nImages without labels:\")\n",
    "        for f in sorted(images_without_labels)[:10]:\n",
    "            print(\" \", f)\n",
    "\n",
    "    if labels_without_images:\n",
    "        print(\"\\nLabels without images:\")\n",
    "        for f in sorted(labels_without_images)[:10]:\n",
    "            print(\" \", f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d6646",
   "metadata": {},
   "source": [
    "## ‚úÖ Preprocessing + preparation (clean ‚Üí resize/normalize ‚Üí augment ‚Üí YOLO labels)\n",
    "\n",
    "This section:\n",
    "- Cleans YOLO labels (removes invalid boxes, clips to bounds, removes duplicates)\n",
    "- Resizes images to a fixed `imgsz` (letterbox) and updates labels\n",
    "- Applies data augmentation (train only)\n",
    "- Writes a new YOLOv8-ready dataset folder and `data.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ab508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install deps (Colab)\n",
    "!pip -q install albumentations opencv-python pyyaml\n",
    "\n",
    "import os, glob, math, shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- CONFIG ----\n",
    "DATA_ROOT = \"/content/Vechiles-2\"      # change if your folder name differs\n",
    "OUT_ROOT  = \"/content/Vechiles-2-prep\" # output dataset (YOLOv8 format)\n",
    "IMGSZ     = 640                        # model input size (e.g., 640 / 832 / 1024)\n",
    "AUG_PER_IMAGE = 2                      # augmentations per train image\n",
    "MIN_BOX_AREA_PX = 16                   # drop very tiny boxes (area in pixels)\n",
    "DUP_IOU = 0.98                         # IoU threshold to treat boxes as duplicates (same class)\n",
    "# ----------------\n",
    "\n",
    "SPLITS = []\n",
    "for s in [\"train\", \"val\", \"valid\", \"test\"]:\n",
    "    if os.path.isdir(os.path.join(DATA_ROOT, s, \"images\")) and os.path.isdir(os.path.join(DATA_ROOT, s, \"labels\")):\n",
    "        SPLITS.append(s)\n",
    "\n",
    "print(\"Detected splits:\", SPLITS)\n",
    "assert len(SPLITS) > 0, \"No splits found. Expected folders like DATA_ROOT/train/images and DATA_ROOT/train/labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42863cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_xyxy_px(yolo_box, w, h):\n",
    "    # yolo_box: (xc,yc,bw,bh) normalized -> xyxy in pixels\n",
    "    xc, yc, bw, bh = yolo_box\n",
    "    x1 = (xc - bw/2) * w\n",
    "    y1 = (yc - bh/2) * h\n",
    "    x2 = (xc + bw/2) * w\n",
    "    y2 = (yc + bh/2) * h\n",
    "    return np.array([x1, y1, x2, y2], dtype=float)\n",
    "\n",
    "def xyxy_px_to_yolo(xyxy, w, h):\n",
    "    x1, y1, x2, y2 = xyxy\n",
    "    bw = max(0.0, x2 - x1)\n",
    "    bh = max(0.0, y2 - y1)\n",
    "    xc = x1 + bw/2\n",
    "    yc = y1 + bh/2\n",
    "    return np.array([xc / w, yc / h, bw / w, bh / h], dtype=float)\n",
    "\n",
    "def clip_xyxy(xyxy, w, h):\n",
    "    x1, y1, x2, y2 = xyxy\n",
    "    x1 = max(0.0, min(x1, w - 1.0))\n",
    "    y1 = max(0.0, min(y1, h - 1.0))\n",
    "    x2 = max(0.0, min(x2, w - 1.0))\n",
    "    y2 = max(0.0, min(y2, h - 1.0))\n",
    "    return np.array([x1, y1, x2, y2], dtype=float)\n",
    "\n",
    "def area_xyxy(xyxy):\n",
    "    x1, y1, x2, y2 = xyxy\n",
    "    return max(0.0, x2 - x1) * max(0.0, y2 - y1)\n",
    "\n",
    "def iou_xyxy(a, b):\n",
    "    ax1, ay1, ax2, ay2 = a\n",
    "    bx1, by1, bx2, by2 = b\n",
    "    ix1, iy1 = max(ax1, bx1), max(ay1, by1)\n",
    "    ix2, iy2 = min(ax2, bx2), min(ay2, by2)\n",
    "    inter = max(0.0, ix2 - ix1) * max(0.0, iy2 - iy1)\n",
    "    ua = area_xyxy(a) + area_xyxy(b) - inter\n",
    "    return inter / ua if ua > 0 else 0.0\n",
    "\n",
    "def remove_duplicates_xyxy(boxes_xyxy, cls_ids, iou_thresh=0.98):\n",
    "    # keep larger boxes first\n",
    "    order = sorted(range(len(boxes_xyxy)), key=lambda i: area_xyxy(boxes_xyxy[i]), reverse=True)\n",
    "    keep = []\n",
    "    used = [False]*len(order)\n",
    "    for ii, i in enumerate(order):\n",
    "        if used[ii]:\n",
    "            continue\n",
    "        keep.append(i)\n",
    "        for jj, j in enumerate(order):\n",
    "            if used[jj] or jj == ii:\n",
    "                continue\n",
    "            if cls_ids[j] != cls_ids[i]:\n",
    "                continue\n",
    "            if iou_xyxy(boxes_xyxy[i], boxes_xyxy[j]) >= iou_thresh:\n",
    "                used[jj] = True\n",
    "    keep_boxes = [boxes_xyxy[i] for i in keep]\n",
    "    keep_cls = [cls_ids[i] for i in keep]\n",
    "    return keep_boxes, keep_cls\n",
    "\n",
    "def read_yolo_label(path):\n",
    "    boxes, cls_ids = [], []\n",
    "    if not os.path.exists(path):\n",
    "        return boxes, cls_ids\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            c = int(float(parts[0]))\n",
    "            xc, yc, bw, bh = map(float, parts[1:])\n",
    "            boxes.append([xc, yc, bw, bh])\n",
    "            cls_ids.append(c)\n",
    "    return boxes, cls_ids\n",
    "\n",
    "def write_yolo_label(path, boxes, cls_ids):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for b, c in zip(boxes, cls_ids):\n",
    "            xc, yc, bw, bh = b\n",
    "            f.write(f\"{c} {xc:.6f} {yc:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "\n",
    "def letterbox(image, new_size=640, color=(114,114,114)):\n",
    "    # Resize with padding to (new_size,new_size). Returns image, scale, pad (dw,dh).\n",
    "    h, w = image.shape[:2]\n",
    "    r = min(new_size / h, new_size / w)\n",
    "    new_unpad = (int(round(w * r)), int(round(h * r)))\n",
    "    resized = cv2.resize(image, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    dw = new_size - new_unpad[0]\n",
    "    dh = new_size - new_unpad[1]\n",
    "    dw /= 2\n",
    "    dh /= 2\n",
    "\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "\n",
    "    padded = cv2.copyMakeBorder(resized, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    return padded, r, (left, top)\n",
    "\n",
    "def clean_yolo_boxes(yolo_boxes, cls_ids, w, h, min_area_px=16, dup_iou=0.98):\n",
    "    # Clip boxes, remove invalid/small, remove duplicates (same class).\n",
    "    cleaned_boxes, cleaned_cls = [], []\n",
    "    for b, c in zip(yolo_boxes, cls_ids):\n",
    "        if any(math.isnan(float(x)) for x in b):\n",
    "            continue\n",
    "        xc, yc, bw, bh = map(float, b)\n",
    "        if bw <= 0 or bh <= 0:\n",
    "            continue\n",
    "\n",
    "        xyxy = yolo_to_xyxy_px((xc, yc, bw, bh), w, h)\n",
    "        xyxy = clip_xyxy(xyxy, w, h)\n",
    "        if area_xyxy(xyxy) < min_area_px:\n",
    "            continue\n",
    "\n",
    "        yolo = xyxy_px_to_yolo(xyxy, w, h)\n",
    "        yolo = np.clip(yolo, 0.0, 1.0)\n",
    "        cleaned_boxes.append(yolo.tolist())\n",
    "        cleaned_cls.append(int(c))\n",
    "\n",
    "    if len(cleaned_boxes) > 1:\n",
    "        boxes_xyxy = [yolo_to_xyxy_px(b, w, h) for b in cleaned_boxes]\n",
    "        boxes_xyxy, cleaned_cls = remove_duplicates_xyxy(boxes_xyxy, cleaned_cls, iou_thresh=dup_iou)\n",
    "        cleaned_boxes = [np.clip(xyxy_px_to_yolo(b, w, h), 0.0, 1.0).tolist() for b in boxes_xyxy]\n",
    "\n",
    "    return cleaned_boxes, cleaned_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b7a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations (train only). Albumentations handles bbox updates correctly.\n",
    "augmenter = A.Compose(\n",
    "    [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Affine(scale=(0.85, 1.15), translate_percent=(0.0, 0.05), rotate=(-12, 12), p=0.8),\n",
    "        A.RandomResizedCrop(height=IMGSZ, width=IMGSZ, scale=(0.75, 1.0), ratio=(0.9, 1.1), p=0.6),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"], min_visibility=0.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91200730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Create output folders\n",
    "for split in SPLITS:\n",
    "    Path(OUT_ROOT, \"images\", split).mkdir(parents=True, exist_ok=True)\n",
    "    Path(OUT_ROOT, \"labels\", split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "image_exts = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "stats = {s: {\"images\":0, \"kept_boxes\":0, \"dropped_boxes\":0} for s in SPLITS}\n",
    "\n",
    "for split in SPLITS:\n",
    "    in_img_dir = os.path.join(DATA_ROOT, split, \"images\")\n",
    "    in_lbl_dir = os.path.join(DATA_ROOT, split, \"labels\")\n",
    "    out_img_dir = os.path.join(OUT_ROOT, \"images\", split)\n",
    "    out_lbl_dir = os.path.join(OUT_ROOT, \"labels\", split)\n",
    "\n",
    "    img_files = []\n",
    "    for ext in image_exts:\n",
    "        img_files.extend(glob.glob(os.path.join(in_img_dir, f\"*{ext}\")))\n",
    "    img_files = sorted(img_files)\n",
    "\n",
    "    for img_path in tqdm(img_files, desc=f\"Preprocess {split}\"):\n",
    "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        lbl_path = os.path.join(in_lbl_dir, base + \".txt\")\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        yolo_boxes, cls_ids = read_yolo_label(lbl_path)\n",
    "        before = len(yolo_boxes)\n",
    "\n",
    "        # clean labels at original resolution\n",
    "        yolo_boxes, cls_ids = clean_yolo_boxes(yolo_boxes, cls_ids, w, h, min_area_px=MIN_BOX_AREA_PX, dup_iou=DUP_IOU)\n",
    "        after_clean = len(yolo_boxes)\n",
    "\n",
    "        # resize/normalize image to IMGSZ with letterbox\n",
    "        img_lb, r, (padx, pady) = letterbox(img, new_size=IMGSZ)\n",
    "\n",
    "        # update boxes to new letterboxed coords\n",
    "        new_boxes, new_cls = [], []\n",
    "        for b, c in zip(yolo_boxes, cls_ids):\n",
    "            xyxy = yolo_to_xyxy_px(b, w, h)  # original px\n",
    "            xyxy *= r\n",
    "            xyxy[[0,2]] += padx\n",
    "            xyxy[[1,3]] += pady\n",
    "            xyxy = clip_xyxy(xyxy, IMGSZ, IMGSZ)\n",
    "            if area_xyxy(xyxy) < MIN_BOX_AREA_PX:\n",
    "                continue\n",
    "            new_boxes.append(np.clip(xyxy_px_to_yolo(xyxy, IMGSZ, IMGSZ), 0.0, 1.0).tolist())\n",
    "            new_cls.append(int(c))\n",
    "\n",
    "        # write base resized sample\n",
    "        out_img_path = os.path.join(out_img_dir, base + \".jpg\")\n",
    "        out_lbl_path = os.path.join(out_lbl_dir, base + \".txt\")\n",
    "        cv2.imwrite(out_img_path, img_lb)\n",
    "        write_yolo_label(out_lbl_path, new_boxes, new_cls)\n",
    "\n",
    "        stats[split][\"images\"] += 1\n",
    "        stats[split][\"kept_boxes\"] += len(new_boxes)\n",
    "        stats[split][\"dropped_boxes\"] += (before - after_clean) + max(0, after_clean - len(new_boxes))\n",
    "\n",
    "        # augment only train split\n",
    "        if split == \"train\" and AUG_PER_IMAGE > 0 and len(new_boxes) > 0:\n",
    "            for k in range(AUG_PER_IMAGE):\n",
    "                aug = augmenter(image=img_lb, bboxes=new_boxes, class_labels=new_cls)\n",
    "                aug_img = aug[\"image\"]\n",
    "                aug_boxes = list(aug[\"bboxes\"])\n",
    "                aug_cls = list(aug[\"class_labels\"])\n",
    "\n",
    "                # clean after augmentation (tiny boxes after crop)\n",
    "                filt_boxes, filt_cls = [], []\n",
    "                for bb, cc in zip(aug_boxes, aug_cls):\n",
    "                    xyxy = yolo_to_xyxy_px(bb, IMGSZ, IMGSZ)\n",
    "                    xyxy = clip_xyxy(xyxy, IMGSZ, IMGSZ)\n",
    "                    if area_xyxy(xyxy) >= MIN_BOX_AREA_PX:\n",
    "                        filt_boxes.append(np.clip(xyxy_px_to_yolo(xyxy, IMGSZ, IMGSZ), 0.0, 1.0).tolist())\n",
    "                        filt_cls.append(int(cc))\n",
    "\n",
    "                aug_name = f\"{base}_aug{k}\"\n",
    "                cv2.imwrite(os.path.join(out_img_dir, aug_name + \".jpg\"), aug_img)\n",
    "                write_yolo_label(os.path.join(out_lbl_dir, aug_name + \".txt\"), filt_boxes, filt_cls)\n",
    "\n",
    "print(\"‚úÖ Done preprocessing.\")\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875e668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data.yaml for YOLOv8\n",
    "# If you know the class names, set NAMES = [\"car\", \"bus\", ...] below.\n",
    "\n",
    "NAMES = None  # e.g. [\"car\",\"bus\",\"truck\",\"motorcycle\",\"person\"]\n",
    "\n",
    "if NAMES is None:\n",
    "    all_cls = set()\n",
    "    for split in SPLITS:\n",
    "        for p in glob.glob(os.path.join(OUT_ROOT, \"labels\", split, \"*.txt\")):\n",
    "            with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "                for line in f:\n",
    "                    line=line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    all_cls.add(int(float(line.split()[0])))\n",
    "    n = (max(all_cls)+1) if all_cls else 1\n",
    "    NAMES = [f\"class_{i}\" for i in range(n)]\n",
    "\n",
    "data_yaml = {\n",
    "    \"path\": OUT_ROOT,\n",
    "    \"train\": \"images/train\" if \"train\" in SPLITS else f\"images/{SPLITS[0]}\",\n",
    "    \"val\": \"images/val\" if \"val\" in SPLITS else (\"images/valid\" if \"valid\" in SPLITS else f\"images/{SPLITS[0]}\"),\n",
    "    \"names\": {i:name for i, name in enumerate(NAMES)}\n",
    "}\n",
    "\n",
    "yaml_path = os.path.join(OUT_ROOT, \"data.yaml\")\n",
    "with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(data_yaml, f, sort_keys=False)\n",
    "\n",
    "print(\"Wrote:\", yaml_path)\n",
    "print(data_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03657d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv8 on the preprocessed dataset (optional)\n",
    "# !pip -q install ultralytics\n",
    "# !yolo detect train model=yolov8n.pt data=/content/Vechiles-2-prep/data.yaml imgsz=640 epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dcRtFMI_lIFr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zAqqqtAAlJdD"
   },
   "outputs": [],
   "source": [
    "images_dir = \"/content/Vechiles-2/train/images\"  # change if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZPnBpOClNau",
    "outputId": "b5a7afb2-a0ce-43c7-906f-7da25913d37d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Converted to RGB: 0\n",
      "‚è≠Ô∏è Already RGB (skipped): 8048\n"
     ]
    }
   ],
   "source": [
    "converted = 0\n",
    "skipped = 0\n",
    "\n",
    "for filename in os.listdir(images_dir):\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        img_path = os.path.join(images_dir, filename)\n",
    "\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                # Check image mode\n",
    "                if img.mode != \"RGB\":\n",
    "                    img = img.convert(\"RGB\")\n",
    "                    img.save(img_path)\n",
    "                    converted += 1\n",
    "                else:\n",
    "                    skipped += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {filename}: {e}\")\n",
    "\n",
    "print(f\"‚úÖ Converted to RGB: {converted}\")\n",
    "print(f\"‚è≠Ô∏è Already RGB (skipped): {skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YjR8soUglR02"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73CAEeYylnaK",
    "outputId": "4e6a39ad-44eb-4953-aafa-77410ac09fc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Auto-oriented images: 8048\n",
      "‚è≠Ô∏è No orientation change needed: 0\n"
     ]
    }
   ],
   "source": [
    "fixed = 0\n",
    "skipped = 0\n",
    "\n",
    "for filename in os.listdir(images_dir):\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "        img_path = os.path.join(images_dir, filename)\n",
    "\n",
    "        try:\n",
    "            with Image.open(img_path) as img:\n",
    "                # Apply EXIF-based auto orientation\n",
    "                img_oriented = ImageOps.exif_transpose(img)\n",
    "\n",
    "                # Save back only if something changed\n",
    "                if img_oriented != img:\n",
    "                    img_oriented.save(img_path)\n",
    "                    fixed += 1\n",
    "                else:\n",
    "                    skipped += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {filename}: {e}\")\n",
    "\n",
    "print(f\"üîÑ Auto-oriented images: {fixed}\")\n",
    "print(f\"‚è≠Ô∏è No orientation change needed: {skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BqV97adMm5AQ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e37IhauxnAAH"
   },
   "outputs": [],
   "source": [
    "base_path = \"/content/Vechiles-2/train\"\n",
    "images_dir = os.path.join(base_path, \"images\")\n",
    "labels_dir = os.path.join(base_path, \"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjo4mivcnChO",
    "outputId": "aaf2b7c1-7c21-403d-fd5f-505ec8f99db0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IMAGE SIZE ANALYSIS ===\n",
      "Total images: 8048\n",
      "Min size: 640x640\n",
      "Max size: 640x640\n",
      "Avg size: 640x640\n"
     ]
    }
   ],
   "source": [
    "image_sizes = []\n",
    "\n",
    "for img_name in os.listdir(images_dir):\n",
    "    if img_name.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        img = cv2.imread(os.path.join(images_dir, img_name))\n",
    "        h, w, _ = img.shape\n",
    "        image_sizes.append((w, h))\n",
    "\n",
    "widths, heights = zip(*image_sizes)\n",
    "\n",
    "print(\"=== IMAGE SIZE ANALYSIS ===\")\n",
    "print(f\"Total images: {len(image_sizes)}\")\n",
    "print(f\"Min size: {min(widths)}x{min(heights)}\")\n",
    "print(f\"Max size: {max(widths)}x{max(heights)}\")\n",
    "print(f\"Avg size: {int(np.mean(widths))}x{int(np.mean(heights))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Taj1l2g7nNxn",
    "outputId": "f2733f41-5dcc-4db3-ba4f-d06ba28d463b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EMPTY LABELS ===\n",
      "Empty label files: 0\n"
     ]
    }
   ],
   "source": [
    "empty_labels = []\n",
    "\n",
    "for label_name in os.listdir(labels_dir):\n",
    "    label_path = os.path.join(labels_dir, label_name)\n",
    "    if os.path.getsize(label_path) == 0:\n",
    "        empty_labels.append(label_name)\n",
    "\n",
    "print(\"\\n=== EMPTY LABELS ===\")\n",
    "print(f\"Empty label files: {len(empty_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNoFvVuSnQpi",
    "outputId": "053f0324-67b2-4909-b58f-1847221d80ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLASS DISTRIBUTION ===\n",
      "Class 3: 15656\n",
      "Class 1: 4237\n",
      "Class 4: 21294\n",
      "Class 2: 12357\n",
      "Class 0: 412\n"
     ]
    }
   ],
   "source": [
    "class_counter = Counter()\n",
    "\n",
    "for label_name in os.listdir(labels_dir):\n",
    "    with open(os.path.join(labels_dir, label_name)) as f:\n",
    "        for line in f:\n",
    "            class_id = int(line.split()[0])\n",
    "            class_counter[class_id] += 1\n",
    "\n",
    "print(\"\\n=== CLASS DISTRIBUTION ===\")\n",
    "for cls, count in class_counter.items():\n",
    "    print(f\"Class {cls}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtMwD8PGnUhv",
    "outputId": "77483d34-ec85-47c2-f465-28e2b490defa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BOUNDING BOX ANALYSIS ===\n",
      "Total boxes: 53956\n",
      "Avg box area (%): 1.28\n",
      "Small boxes (<1%): 35632\n"
     ]
    }
   ],
   "source": [
    "box_areas = []\n",
    "small_boxes = 0\n",
    "\n",
    "for label_name in os.listdir(labels_dir):\n",
    "    with open(os.path.join(labels_dir, label_name)) as f:\n",
    "        for line in f:\n",
    "            _, _, _, w, h = map(float, line.split())\n",
    "            area = w * h\n",
    "            box_areas.append(area)\n",
    "\n",
    "            if area < 0.01:  # <1% of image\n",
    "                small_boxes += 1\n",
    "\n",
    "print(\"\\n=== BOUNDING BOX ANALYSIS ===\")\n",
    "print(f\"Total boxes: {len(box_areas)}\")\n",
    "print(f\"Avg box area (%): {np.mean(box_areas)*100:.2f}\")\n",
    "print(f\"Small boxes (<1%): {small_boxes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sZAOcyVnayc",
    "outputId": "ba2f22d2-301f-4f4a-bd5e-6edf1ea057b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ASPECT RATIO ===\n",
      "Avg aspect ratio: 1.35\n"
     ]
    }
   ],
   "source": [
    "aspect_ratios = []\n",
    "\n",
    "for label_name in os.listdir(labels_dir):\n",
    "    with open(os.path.join(labels_dir, label_name)) as f:\n",
    "        for line in f:\n",
    "            _, _, _, w, h = map(float, line.split())\n",
    "            if h > 0:\n",
    "                aspect_ratios.append(w / h)\n",
    "\n",
    "print(\"\\n=== ASPECT RATIO ===\")\n",
    "print(f\"Avg aspect ratio: {np.mean(aspect_ratios):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMA5H6ACHSj5pdEIJyPMspS",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
